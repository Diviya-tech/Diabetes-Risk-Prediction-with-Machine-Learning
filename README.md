[# ğŸ©º Diabetes Risk Prediction with KNN Classifier

![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python)
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-ML-red?logo=scikit-learn)
![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange?logo=jupyter)
![License](https://img.shields.io/badge/License-MIT-green)

An end-to-end machine learning pipeline to predict diabetes risk using K-Nearest Neighbors (KNN) classification â€” covering data preprocessing, exploratory analysis, feature selection, model tuning, and evaluation.

---

## ğŸ¯ Problem Statement

Diabetes affects millions globally and early detection significantly improves patient outcomes. This project builds a binary classification model to predict whether a patient is diabetic based on clinical health indicators such as glucose levels, BMI, and age.

---

## ğŸ“Š Dataset

**Source:** [Pima Indians Diabetes Dataset â€“ Kaggle](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database)

| Property | Details |
|----------|---------|
| Samples | 768 patients |
| Features | 8 clinical indicators |
| Target | Binary â€” Diabetic (1) / Not Diabetic (0) |
| Class Split | 500 non-diabetic, 268 diabetic |

---

## ğŸ” Approach

### 1ï¸âƒ£ Exploratory Data Analysis
- Identified missing/zero values in clinical features (invalid medical readings)
- Analyzed feature distributions and class imbalance
- Computed Pearson correlation to understand feature relationships

### 2ï¸âƒ£ Data Preprocessing
- Replaced biologically invalid zero values with median imputation
- Applied StandardScaler normalization for KNN distance calculations
- Compared correlation structure before and after preprocessing

### 3ï¸âƒ£ Feature Selection
- Used feature importance scoring to identify top predictors
- Selected top 3 features: **Glucose, BMI, Age**

### 4ï¸âƒ£ Model Tuning
- Applied Elbow Method to find optimal K value
- Evaluated error rate across K = 5 to 14
- Selected **K = 5** as optimal based on lowest error rate

### 5ï¸âƒ£ Model Evaluation
- Evaluated using ROC-AUC, confusion matrix, precision, recall

---

## ğŸ“ˆ Results

### Missing Values â€” Before Preprocessing

![Missing Values Heatmap](Results/missing_values_heatmap.png)

> SkinThickness and Insulin had the highest proportion of invalid zero values â€” replaced with median imputation.

---

### Feature Distributions

![Feature Distributions](Results/feature_distributions.png)

> Glucose follows a near-normal distribution. Insulin and SkinThickness show heavy right skew â€” confirming the need for imputation.

---

### Pearson Correlation â€” Before Preprocessing

![Correlation Before](Results/correlation_before.png)

---

### Pearson Correlation â€” After Preprocessing

![Correlation After](Results/correlation_after.png)

> Preprocessing reduced spurious correlations â€” notably Insulin's correlation with SkinThickness dropped from 0.18 â†’ 0.16 after removing invalid zeros.

---

### Elbow Method â€” Optimal K Selection

![Elbow Method](Results/elbow_method.png)

> K = 5 selected as optimal â€” lowest error rate of **0.255** across all tested values.

---

### Top 3 Features Selected for KNN

![Feature Importance](Results/feature_importance.png)

> **Glucose** is by far the strongest predictor, followed by BMI and Age â€” consistent with clinical diabetes risk factors.

---

### ROC Curve â€” KNN (K=5)

![ROC Curve](Results/roc_curve.png)

> **AUC = 0.79** â€” the model significantly outperforms random classification (AUC = 0.5).

---

### Confusion Matrix â€” KNN (K=5)

![Confusion Matrix](Results/confusion_matrix.png)

| Metric | Value |
|--------|-------|
| True Negatives (correctly predicted non-diabetic) | 105 |
| True Positives (correctly predicted diabetic) | 38 |
| False Positives | 20 |
| False Negatives | 29 |
| **Accuracy** | **~74.5%** |
| **AUC-ROC** | **0.79** |

---

### Error Rate vs K Value

![Error Rate vs K](Results/error_rate_kvalue.png)

> Error rate stabilizes around 0.276 for most K values â€” K=5 and K=11 show the lowest error rates.

---

## ğŸ’¡ Key Learnings

- Glucose is the single most important predictor of diabetes risk â€” aligns with clinical evidence
- Zero-value imputation significantly improved model reliability for SkinThickness and Insulin features
- KNN is sensitive to feature scaling â€” StandardScaler was critical before training
- AUC of 0.79 is solid for a KNN baseline; ensemble methods like Random Forest or XGBoost could push this further

---

## ğŸ› ï¸ Tech Stack

`Python` `Scikit-learn` `Pandas` `NumPy` `Matplotlib` `Seaborn` `Jupyter Notebook`

---

## ğŸš€ How to Run

```bash
git clone https://github.com/Diviya-tech/Diabetes-Risk-Prediction-with-Machine-Learning
cd Diabetes-Risk-Prediction-with-Machine-Learning
pip install -r requirements.txt
jupyter notebook
```

---

## ğŸ“ Project Structure

```
Diabetes-Risk-Prediction-with-Machine-Learning/
â”œâ”€â”€ Results/
â”‚   â”œâ”€â”€ missing_values_heatmap.png
â”‚   â”œâ”€â”€ feature_distributions.png
â”‚   â”œâ”€â”€ correlation_before.png
â”‚   â”œâ”€â”€ correlation_after.png
â”‚   â”œâ”€â”€ elbow_method.png
â”‚   â”œâ”€â”€ feature_importance.png
â”‚   â”œâ”€â”€ roc_curve.png
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â””â”€â”€ error_rate_kvalue.png
â”œâ”€â”€ notebooks/
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ”® Future Improvements

- Compare KNN against Random Forest, XGBoost, and Logistic Regression
- Address class imbalance using SMOTE oversampling
- Build a Streamlit web app for real-time risk prediction
- Explore deep learning approach for improved recall on diabetic class

---

## ğŸ“¬ Connect

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue?style=flat&logo=linkedin)](https://linkedin.com/in/sridivyadasari)
[![GitHub](https://img.shields.io/badge/GitHub-Follow-black?style=flat&logo=github)](https://github.com/Diviya-tech)
](https://diabetes-risk-prediction-with-machine-learning-boyy5wpj7c9bfhh.streamlit.app/)
